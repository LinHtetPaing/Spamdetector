{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from builtins import str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset 'SMSSpamCollection' into variable 'messages'\n",
    "data = [line.rstrip() for line in open('SMSSpamCollection')]\n",
    "# Print number of messages\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "  Read the dataset. Specify the field separator is a tab instead of a comma.\n",
    "  Additionally, add column captions('label' and 'message') for the two fields in the dataset.\n",
    "  To preserve internal quotations in messages, use QUOTE_NONE.\n",
    "  \"\"\"\n",
    "data = pandas.read_csv('SMSSpamCollection', sep='\\t', quoting=csv.QUOTE_NONE,names=[\"class\",\"message\"])\n",
    "# Print first 5 records\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       message\n",
      "class         \n",
      "ham       4827\n",
      "spam       747\n"
     ]
    }
   ],
   "source": [
    "# Group by class and count\n",
    "print(messages.groupby('class').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Go, until, jurong, point, crazy, Available, o...\n",
      "1                       [Ok, lar, Joking, wif, u, oni]\n",
      "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
      "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
      "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split messages into individual words\n",
    "def SplitIntoWords(message):\n",
    "    message = str(message)\n",
    "    return TextBlob(message).words\n",
    "# This is what the first 5 record look when splitted onto individual words\n",
    "print(messages.message.head().apply(SplitIntoWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 88)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 1914)\t1\n",
      "  (0, 1947)\t1\n",
      "  (0, 2208)\t1\n",
      "  (0, 2240)\t1\n",
      "  (0, 3039)\t1\n",
      "  (0, 3382)\t1\n",
      "  (0, 3433)\t2\n",
      "  (0, 3778)\t1\n",
      "  (0, 4645)\t1\n",
      "  (0, 5182)\t3\n",
      "  (0, 5215)\t1\n",
      "  (0, 5222)\t1\n",
      "  (0, 5643)\t1\n",
      "  (0, 5690)\t1\n",
      "  (0, 6301)\t1\n",
      "  (0, 7673)\t2\n",
      "  (0, 7801)\t2\n",
      "  (0, 8002)\t1\n",
      "  (0, 8099)\t2\n",
      "  (0, 8495)\t1\n",
      "  (0, 8747)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert each word into its base form\n",
    "def WordsIntoBaseForm(message):\n",
    "    message = str(message).lower()\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]\n",
    "# Convert each message into a vector\n",
    "trainingVector = CountVectorizer(analyzer=WordsIntoBaseForm).fit(data['message'])\n",
    "\n",
    "# View occurence of words in an arbitrary vector. Use 9 for vector #10.\n",
    "message10 = trainingVector.transform([data['message'][9]])\n",
    "print(message10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "First word that appears twice: free2day\n",
      "word that appears three times: model..sony\n"
     ]
    }
   ],
   "source": [
    "# Print message #10  for comparison\n",
    "print(data['message'][9])\n",
    "# Identify repeated words\n",
    "print('First word that appears twice:',\n",
    "     trainingVector.get_feature_names()[3437])\n",
    "print('word that appears three times:',\n",
    "     trainingVector.get_feature_names()[5192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bages of words for the entire training dataset\n",
    "messagesBagOfWords = trainingVector.fit_transform(data['message'].values)\n",
    "# weight frequency and inverse Document frequency\n",
    "messagesTfidf = TfidfTransformer().fit(messagesBagOfWords).transform(messagesBagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "spamDetector = MultinomialNB().fit(messagesTfidf,data['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message [ England v Macedonia - dont miss the goals/team news. Txt ENGLAND to 99999 ] has been classified as  spam\n"
     ]
    }
   ],
   "source": [
    "# Test message\n",
    "example = ['England v Macedonia - dont miss the goals/team news. Txt ENGLAND to 99999']\n",
    "# Result\n",
    "checkResult = spamDetector.predict(trainingVector.transform(example))[0]\n",
    "print('The message [',example[0],'] has been classified as ', checkResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
